{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "A gentle introduction to tf.data with TensorFlow",
      "provenance": [],
      "authorship_tag": "ABX9TyPhdX1K7oyBWWDAM0XmBVmQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rjarun8/ComputerVisionPyImageSearch/blob/main/A_gentle_introduction_to_tf_data_with_TensorFlow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yf7iIgqiVhv9"
      },
      "source": [
        "\n",
        "\n",
        "#A gentle introduction to tf.data with TensorFlow\n",
        "\n",
        "https://www.pyimagesearch.com/2021/06/14/a-gentle-introduction-to-tf-data-with-tensorflow/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6M5ihlvvQCYc",
        "outputId": "86492768-6f81-4cc4-fa54-2cfc7df0c4c2"
      },
      "source": [
        "!wget 'https://pyimagesearch-code-downloads.s3-us-west-2.amazonaws.com/tfdata-intro/tfdata-intro.zip'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-08-07 11:02:06--  https://pyimagesearch-code-downloads.s3-us-west-2.amazonaws.com/tfdata-intro/tfdata-intro.zip\n",
            "Resolving pyimagesearch-code-downloads.s3-us-west-2.amazonaws.com (pyimagesearch-code-downloads.s3-us-west-2.amazonaws.com)... 52.218.137.41\n",
            "Connecting to pyimagesearch-code-downloads.s3-us-west-2.amazonaws.com (pyimagesearch-code-downloads.s3-us-west-2.amazonaws.com)|52.218.137.41|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 586970111 (560M) [binary/octet-stream]\n",
            "Saving to: ‘tfdata-intro.zip’\n",
            "\n",
            "tfdata-intro.zip    100%[===================>] 559.78M  34.5MB/s    in 18s     \n",
            "\n",
            "2021-08-07 11:02:24 (31.2 MB/s) - ‘tfdata-intro.zip’ saved [586970111/586970111]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tAQnKNV3RvJ5"
      },
      "source": [
        "# !unzip '/content/tfdata-intro.zip'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnwoezkNR01e"
      },
      "source": [
        "import os\n",
        "os.chdir('/content/tfdata-intro')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZkHr_uNgR8y-"
      },
      "source": [
        "# import the necessary packages\n",
        "import time\n",
        "def benchmark(datasetGen, numSteps):\n",
        "\t# start our timer\n",
        "\tstart = time.time()\n",
        "\t# loop over the provided number of steps\n",
        "\tfor i in range(0, numSteps):\n",
        "\t\t# get the next batch of data (we don't do anything with the\n",
        "\t\t# data since we are just benchmarking)\n",
        "\t\t(images, labels) = next(datasetGen)\n",
        "\t# stop the timer\n",
        "\tend = time.time()\n",
        "\t# return the difference between end and start times\n",
        "\treturn (end - start)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XlD7MjDgTJRZ"
      },
      "source": [
        "# import the necessary packages\n",
        "from pyimagesearch.helpers import benchmark\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.datasets import cifar100\n",
        "from tensorflow.data import AUTOTUNE\n",
        "import tensorflow as tf"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2xCjl1TKTVTu",
        "outputId": "63bac93c-de66-4745-f2ac-3f38aadf635f"
      },
      "source": [
        "# initialize the batch size and number of steps\n",
        "BS = 64\n",
        "NUM_STEPS = 5000\n",
        "# load the CIFAR-10 dataset from\n",
        "print(\"[INFO] loading the cifar100 dataset...\")\n",
        "((trainX, trainY), (testX, testY)) = cifar100.load_data()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] loading the cifar100 dataset...\n",
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "169009152/169001437 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JV73HevCTZmR",
        "outputId": "cec4fe4e-8d2e-4538-8e7f-d65fc915bf31"
      },
      "source": [
        "# create a standard image generator object\n",
        "print(\"[INFO] creating a ImageDataGenerator object...\")\n",
        "imageGen = ImageDataGenerator()\n",
        "dataGen = imageGen.flow(\n",
        "\tx=trainX, y=trainY,\n",
        "\tbatch_size=BS, shuffle=True)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] creating a ImageDataGenerator object...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rwXW7xi4Tcx2",
        "outputId": "4f7031c7-f549-4c59-fabc-dfb71831d0a6"
      },
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices((trainX, trainY))\n",
        "# build the data input pipeline\n",
        "print(\"[INFO] creating a tf.data input pipeline..\")\n",
        "dataset = (dataset\n",
        "\t.shuffle(1024)\n",
        "\t.cache()\n",
        "\t.repeat()\n",
        "\t.batch(BS)\n",
        "\t.prefetch(AUTOTUNE)\n",
        ")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] creating a tf.data input pipeline..\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KoUTJsFHTipU",
        "outputId": "0c1879a9-e114-46fe-af68-2885b56d50cd"
      },
      "source": [
        "# benchmark the image data generator and display the number of data\n",
        "# points generated, along with the time taken to perform the\n",
        "# operation\n",
        "totalTime = benchmark(dataGen, NUM_STEPS)\n",
        "print(\"[INFO] ImageDataGenerator generated {} images in \" \\\n",
        "\t  \" {:.2f} seconds...\".format(\n",
        "\tBS * NUM_STEPS, totalTime))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] ImageDataGenerator generated 320000 images in  6.67 seconds...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-eP35Eh1T8MW",
        "outputId": "3c68eabd-d7ae-4a4d-c445-d42cfb3a4bc7"
      },
      "source": [
        "# create a dataset iterator, benchmark the tf.data pipeline, and\n",
        "# display the number of data points generator along with the time taken\n",
        "datasetGen = iter(dataset)\n",
        "totalTime = benchmark(datasetGen, NUM_STEPS)\n",
        "print(\"[INFO] tf.data generated {} images in {:.2f} seconds...\".format(\n",
        "\tBS * NUM_STEPS, totalTime))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] tf.data generated 320000 images in 1.27 seconds...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qsniETl9UJn0",
        "outputId": "b5db9297-4f1d-44a0-ecf5-71344a5b75ab"
      },
      "source": [
        "!python reading_from_memory.py"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-08-07 11:13:12.136862: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "[INFO] loading the cifar100 dataset...\n",
            "[INFO] creating a ImageDataGenerator object...\n",
            "2021-08-07 11:13:16.306101: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
            "2021-08-07 11:13:16.317981: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2021-08-07 11:13:16.318039: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (1c86dac841a5): /proc/driver/nvidia/version does not exist\n",
            "[INFO] creating a tf.data input pipeline..\n",
            "[INFO] ImageDataGenerator generated 320000 images in  6.45 seconds...\n",
            "[INFO] tf.data generated 320000 images in 1.21 seconds...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9TyNRtTURkU"
      },
      "source": [
        "from pyimagesearch.helpers import benchmark\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.data import AUTOTUNE\n",
        "from imutils import paths\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import argparse\n",
        "import os"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySVqg8e3Ucec"
      },
      "source": [
        "def load_images(imagePath):\n",
        "\t# read the image from disk, decode it, resize it, and scale the\n",
        "\t# pixels intensities to the range [0, 1]\n",
        "\timage = tf.io.read_file(imagePath)\n",
        "\timage = tf.image.decode_png(image, channels=3)\n",
        "\timage = tf.image.resize(image, (96, 96)) / 255.0\n",
        "\t# grab the label and encode it\n",
        "\tlabel = tf.strings.split(imagePath, os.path.sep)[-2]\n",
        "\toneHot = label == classNames\n",
        "\tencodedLabel = tf.argmax(oneHot)\n",
        "\t# return the image and the integer encoded label\n",
        "\treturn (image, encodedLabel)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WhJbgeUjUstA",
        "outputId": "d45ec23f-073a-41d8-fbb6-8fb70ccfb1d3"
      },
      "source": [
        "# initialize batch size and number of steps\n",
        "BS = 64\n",
        "NUM_STEPS = 1000\n",
        "# grab the list of images in our dataset directory and grab all\n",
        "# unique class names\n",
        "print(\"[INFO] loading image paths...\")\n",
        "imagePaths = list(paths.list_images(r'/content/tfdata-intro/fruits'))\n",
        "classNames = np.array(sorted(os.listdir(r'/content/tfdata-intro/fruits')))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] loading image paths...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gq3bNERvVCKC",
        "outputId": "2ad64d7c-8d8f-4776-d975-4603811179b2"
      },
      "source": [
        "print(\"[INFO] creating a tf.data input pipeline..\")\n",
        "dataset = tf.data.Dataset.from_tensor_slices(imagePaths)\n",
        "dataset = (dataset\n",
        "\t.shuffle(1024)\n",
        "\t.map(load_images, num_parallel_calls=AUTOTUNE)\n",
        "\t.cache()\n",
        "\t.repeat()\n",
        "\t.batch(BS)\n",
        "\t.prefetch(AUTOTUNE)\n",
        ")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] creating a tf.data input pipeline..\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wh9W4HizVERS",
        "outputId": "1347b4a8-a485-43c3-add0-b49c66e5b6be"
      },
      "source": [
        "# create a standard image generator object\n",
        "print(\"[INFO] creating a ImageDataGenerator object...\")\n",
        "imageGen = ImageDataGenerator(rescale=1.0/255)\n",
        "dataGen = imageGen.flow_from_directory(\n",
        "\tr'/content/tfdata-intro/fruits',\n",
        "\ttarget_size=(96, 96),\n",
        "\tbatch_size=BS,\n",
        "\tclass_mode=\"categorical\",\n",
        "\tcolor_mode=\"rgb\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] creating a ImageDataGenerator object...\n",
            "Found 6688 images belonging to 7 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D2fgua4XVH6P",
        "outputId": "87f8a041-aa70-4b97-d6bd-1779b96348df"
      },
      "source": [
        "# benchmark the image data generator and display the number of data\n",
        "# points generated, along with the time taken to perform the\n",
        "# operation\n",
        "totalTime = benchmark(dataGen, NUM_STEPS)\n",
        "print(\"[INFO] ImageDataGenerator generated {} images in \" \\\n",
        "\t  \" {:.2f} seconds...\".format(\n",
        "\tBS * NUM_STEPS, totalTime))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] ImageDataGenerator generated 64000 images in  328.71 seconds...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_sJ2JFz6VPhk",
        "outputId": "a97cb58d-8d07-4b33-a3f0-d7ad4cbeee25"
      },
      "source": [
        "# create a dataset iterator, benchmark the tf.data pipeline, and\n",
        "# display the number of data points generated, along with the time\n",
        "# taken\n",
        "datasetGen = iter(dataset)\n",
        "totalTime = benchmark(datasetGen, NUM_STEPS)\n",
        "print(\"[INFO] tf.data generated {} images in {:.2f} seconds...\".format(\n",
        "\tBS * NUM_STEPS, totalTime))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] tf.data generated 64000 images in 15.18 seconds...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAyEX9H8VUae"
      },
      "source": [
        "python reading_from_disk.py --dataset fruits"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Qb6pP_0VwER"
      },
      "source": [
        "#Data pipelines with tf.data and TensorFlow\n",
        "\n",
        "https://www.pyimagesearch.com/2021/06/21/data-pipelines-with-tf-data-and-tensorflow/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qdz51aFwVyg9",
        "outputId": "f0c184f9-8583-4643-b48e-c871ef9ed476"
      },
      "source": [
        "!wget 'https://pyimagesearch-code-downloads.s3-us-west-2.amazonaws.com/tfdata-pipelines/tfdata-pipelines.zip'"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-08-07 11:26:28--  https://pyimagesearch-code-downloads.s3-us-west-2.amazonaws.com/tfdata-pipelines/tfdata-pipelines.zip\n",
            "Resolving pyimagesearch-code-downloads.s3-us-west-2.amazonaws.com (pyimagesearch-code-downloads.s3-us-west-2.amazonaws.com)... 52.218.217.225\n",
            "Connecting to pyimagesearch-code-downloads.s3-us-west-2.amazonaws.com (pyimagesearch-code-downloads.s3-us-west-2.amazonaws.com)|52.218.217.225|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 46749 (46K) [application/zip]\n",
            "Saving to: ‘tfdata-pipelines.zip’\n",
            "\n",
            "tfdata-pipelines.zi 100%[===================>]  45.65K  --.-KB/s    in 0.08s   \n",
            "\n",
            "2021-08-07 11:26:28 (554 KB/s) - ‘tfdata-pipelines.zip’ saved [46749/46749]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_85tfdKW4E7",
        "outputId": "68844d2d-c789-46bf-e8cc-92a1a985f8ab"
      },
      "source": [
        "os.chdir(r'/content')\n",
        "!unzip 'tfdata-pipelines.zip'"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  tfdata-pipelines.zip\n",
            "   creating: tfdata-pipelines/\n",
            "  inflating: tfdata-pipelines/build_dataset.py  \n",
            "   creating: tfdata-pipelines/datasets/\n",
            "  inflating: tfdata-pipelines/plot.png  \n",
            "   creating: tfdata-pipelines/pyimagesearch/\n",
            " extracting: tfdata-pipelines/pyimagesearch/__init__.py  \n",
            "  inflating: tfdata-pipelines/pyimagesearch/cancernet.py  \n",
            "  inflating: tfdata-pipelines/pyimagesearch/config.py  \n",
            "  inflating: tfdata-pipelines/train_model.py  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yq7NaX3yXD_k"
      },
      "source": [
        "os.chdir(r'/content/tfdata-pipelines')"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12w-Q-k6XeS0",
        "outputId": "3692d88c-bf3b-4650-8c27-a6dc50b224bb"
      },
      "source": [
        "!mkdir datasets"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘datasets’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0tDiHclOXhqV"
      },
      "source": [
        "!mkdir datasets/orig"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N7ec3JU3Xo6_",
        "outputId": "10f5391f-910c-417c-bc65-d4cd664fee19"
      },
      "source": [
        "os.chdir('/content/tfdata-pipelines/datasets/orig')\n",
        "\n",
        "!wget 'https://www.kaggle.com/paultimothymooney/breast-histopathology-images/download'"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-08-07 11:29:12--  https://www.kaggle.com/paultimothymooney/breast-histopathology-images/download\n",
            "Resolving www.kaggle.com (www.kaggle.com)... 35.244.233.98\n",
            "Connecting to www.kaggle.com (www.kaggle.com)|35.244.233.98|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /account/login?titleType=dataset-downloads&showDatasetDownloadSkip=False&messageId=datasetsWelcome&returnUrl=%2Fpaultimothymooney%2Fbreast-histopathology-images%3Fresource%3Ddownload [following]\n",
            "--2021-08-07 11:29:12--  https://www.kaggle.com/account/login?titleType=dataset-downloads&showDatasetDownloadSkip=False&messageId=datasetsWelcome&returnUrl=%2Fpaultimothymooney%2Fbreast-histopathology-images%3Fresource%3Ddownload\n",
            "Reusing existing connection to www.kaggle.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘download’\n",
            "\n",
            "\rdownload                [<=>                 ]       0  --.-KB/s               \rdownload                [ <=>                ]   6.48K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-08-07 11:29:12 (81.9 MB/s) - ‘download’ saved [6632]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tesqmytgaEDD"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_XkL-_FiaEGB"
      },
      "source": [
        "#Data augmentation with tf.data and TensorFlow\n",
        "\n",
        "https://www.pyimagesearch.com/2021/06/28/data-augmentation-with-tf-data-and-tensorflow/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bEfFqV9X8Nc"
      },
      "source": [
        "!wget 'https://pyimagesearch-code-downloads.s3-us-west-2.amazonaws.com/tfdata-data-augmentation/tfdata-data-augmentation.zip'"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}